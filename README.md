# multi-tokernizer-llm

## Install dependancies
```bash
pip install -r requirements.txt
```

## Preprocess data
```bash
python utils/preprocess.py --load_tokenizer
```
Use `--load_tokenizer` to load the tokenizer from the files if you have already saved one.